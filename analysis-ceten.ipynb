{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_GRAM = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lendo arquivo\n",
    "\n",
    "Lendo arquivo CETEN.xml e adicionando _dummy characters_ nas linhas com o tamanho do n-gram\n",
    "\n",
    "- `<s>`: início da sentença\n",
    "- `</s>`: fim da sentença"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_line(line, n_gram=3):\n",
    "    line = line.replace('\\n', '').strip()\n",
    "    line = line.replace('<s> ', '<s> '*(n_gram-1))\n",
    "    line = line.replace(' </s>', ' </s>'*(n_gram-1))\n",
    "    return tuple(line.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1542880/1542880 [00:19<00:00, 78770.41it/s]\n"
     ]
    }
   ],
   "source": [
    "filepath = './data/ceten.xml'\n",
    "lines = []\n",
    "n_lines = -1\n",
    "i = 0\n",
    "with open(filepath) as f:\n",
    "    for line in tqdm(f.readlines()[:n_lines]):\n",
    "        line = process_line(line, N_GRAM+1)\n",
    "        lines.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('<s>', '<s>', 'pt', 'no', 'governo', '</s>', '</s>')"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definindo vocabulário"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1542880/1542880 [00:25<00:00, 60122.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 214439\n",
      "CPU times: user 19.1 s, sys: 4.14 s, total: 23.3 s\n",
      "Wall time: 30.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def get_vocabulary(lines):\n",
    "    vocabulary = {}\n",
    "    for sentence in tqdm(lines):\n",
    "        for word in sentence:\n",
    "            if word not in ['<s>', '</s>']:\n",
    "                vocabulary[word] = vocabulary.get(word, 0) + 1\n",
    "    return vocabulary\n",
    "\n",
    "vocabulary = get_vocabulary(lines)\n",
    "print ('Vocabulary size:', len(vocabulary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extraindo N-grams\n",
    "\n",
    "Os n-gramas de um texto são todas as sentenças formadas por `N` palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 4837.72it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{('<s>', 'hoje'): 3,\n",
       " ('hoje', 'choveu'): 2,\n",
       " ('choveu', 'muito'): 2,\n",
       " ('muito', 'no'): 2,\n",
       " ('no', 'rio'): 1,\n",
       " ('rio', 'de'): 1,\n",
       " ('de', 'janeiro'): 1,\n",
       " ('janeiro', '</s>'): 1,\n",
       " ('no', 'espírito'): 1,\n",
       " ('espírito', 'santo'): 1,\n",
       " ('santo', '</s>'): 1,\n",
       " ('hoje', 'nevou'): 1,\n",
       " ('nevou', 'muito'): 1,\n",
       " ('muito', 'na'): 1,\n",
       " ('na', 'bahía'): 1,\n",
       " ('bahía', '</s>'): 1}"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_n_grams(lines, n=3):\n",
    "    n_grams = {}\n",
    "    for sentence in tqdm(lines):\n",
    "        sentence_length = len(sentence)\n",
    "        start_index = 0\n",
    "        end_index = start_index + n\n",
    "        while end_index <= sentence_length:\n",
    "\n",
    "            n_gram = sentence[start_index:end_index]\n",
    "            n_grams[n_gram] = n_grams.get(n_gram, 0) + 1\n",
    "\n",
    "            start_index +=1\n",
    "            end_index = start_index + n\n",
    "\n",
    "    return n_grams\n",
    "\n",
    "sentence = [\n",
    "    ('<s>', 'hoje', 'choveu', 'muito', 'no', 'rio', 'de', 'janeiro', '</s>'),\n",
    "    ('<s>', 'hoje', 'choveu', 'muito', 'no', 'espírito', 'santo', '</s>'),\n",
    "    ('<s>', 'hoje', 'nevou', 'muito', 'na', 'bahía', '</s>'),\n",
    "]\n",
    "get_n_grams(sentence, n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1542880/1542880 [01:56<00:00, 13254.08it/s]\n"
     ]
    }
   ],
   "source": [
    "n_grams = get_n_grams(lines, n=N_GRAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1542880/1542880 [01:18<00:00, 19554.63it/s]\n"
     ]
    }
   ],
   "source": [
    "n_plus1_grams = get_n_grams(lines, n=N_GRAM+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculando a _Forward Probability_\n",
    "\n",
    "$$P(word|sentence) = \\frac{Count(sentence+word)}{Count(sentence)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ocorrências da sentença ('pesquisa', 'datafolha'): 587\n",
      "Ocorrências da sentença ('pesquisa', 'datafolha', 'revela'): 9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.015332197614991482"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_forward_probability(sentence, word, n_grams, n_plus1_grams, vocabulary):\n",
    "    if word not in vocabulary.keys():\n",
    "        print (f'Word {word} not in vocabulary')\n",
    "        return 0\n",
    "\n",
    "    full_sentence = (*sentence, word)\n",
    "    sentence_occurrences = n_grams.get(sentence, 0)\n",
    "    full_sentence_occurences = n_plus1_grams.get(full_sentence, 0)\n",
    "\n",
    "    print (f'Ocorrências da sentença {sentence}: {sentence_occurrences}')\n",
    "    print (f'Ocorrências da sentença {full_sentence}: {full_sentence_occurences}')\n",
    "\n",
    "    if sentence_occurrences == 0:\n",
    "        return 0\n",
    "\n",
    "    return full_sentence_occurences/sentence_occurrences\n",
    "\n",
    "sentence = ('pesquisa', 'datafolha')\n",
    "next_word = 'revela'\n",
    "prob = get_forward_probability(sentence, next_word, n_grams, n_plus1_grams, vocabulary)\n",
    "prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('pesquisa', 'datafolha')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "('pesquisa', 'datafolha', 'revela')[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('pesquisa', 'datafolha', 'publicada'): 61,\n",
       " ('pesquisa', 'datafolha', 'deve'): 1,\n",
       " ('pesquisa', 'datafolha', 'divulgada'): 25,\n",
       " ('pesquisa', 'datafolha', 'é'): 35,\n",
       " ('pesquisa', 'datafolha', 'debateriam'): 3,\n",
       " ('pesquisa', 'datafolha', 'realizada'): 71,\n",
       " ('pesquisa', 'datafolha', '</s>'): 69,\n",
       " ('pesquisa', 'datafolha', 'sobre'): 26,\n",
       " ('pesquisa', 'datafolha', 'enéas'): 1,\n",
       " ('pesquisa', 'datafolha', 'foi'): 9,\n",
       " ('pesquisa', 'datafolha', 'feita'): 30,\n",
       " ('pesquisa', 'datafolha', 'a'): 6,\n",
       " ('pesquisa', 'datafolha', 'mostra'): 26,\n",
       " ('pesquisa', 'datafolha', 'revela'): 9,\n",
       " ('pesquisa', 'datafolha', 'traz'): 2,\n",
       " ('pesquisa', 'datafolha', 'de'): 24,\n",
       " ('pesquisa', 'datafolha', 'aponta'): 4,\n",
       " ('pesquisa', 'datafolha', 'dos'): 3,\n",
       " ('pesquisa', 'datafolha', 'indica'): 8,\n",
       " ('pesquisa', 'datafolha', 'junto'): 2,\n",
       " ('pesquisa', 'datafolha', 'ele'): 4,\n",
       " ('pesquisa', 'datafolha', 'entre'): 4,\n",
       " ('pesquisa', 'datafolha', 'luiz'): 1,\n",
       " ('pesquisa', 'datafolha', 'lhe'): 2,\n",
       " ('pesquisa', 'datafolha', 'no'): 5,\n",
       " ('pesquisa', 'datafolha', 'ter'): 1,\n",
       " ('pesquisa', 'datafolha', 'considera'): 1,\n",
       " ('pesquisa', 'datafolha', 'não'): 2,\n",
       " ('pesquisa', 'datafolha', 'trinta'): 4,\n",
       " ('pesquisa', 'datafolha', 'repercutiu'): 1,\n",
       " ('pesquisa', 'datafolha', 'que'): 13,\n",
       " ('pesquisa', 'datafolha', 'pelas'): 1,\n",
       " ('pesquisa', 'datafolha', 'em'): 4,\n",
       " ('pesquisa', 'datafolha', 'mostrou'): 5,\n",
       " ('pesquisa', 'datafolha', 'com'): 9,\n",
       " ('pesquisa', 'datafolha', 'surpreendeu'): 1,\n",
       " ('pesquisa', 'datafolha', 'está'): 1,\n",
       " ('pesquisa', 'datafolha', 'e'): 6,\n",
       " ('pesquisa', 'datafolha', 'do'): 3,\n",
       " ('pesquisa', 'datafolha', 'cinquenta'): 1,\n",
       " ('pesquisa', 'datafolha', 'após'): 2,\n",
       " ('pesquisa', 'datafolha', 'apontou'): 5,\n",
       " ('pesquisa', 'datafolha', 'permite'): 1,\n",
       " ('pesquisa', 'datafolha', 'prova'): 1,\n",
       " ('pesquisa', 'datafolha', 'o'): 10,\n",
       " ('pesquisa', 'datafolha', 'mostram'): 2,\n",
       " ('pesquisa', 'datafolha', 'os'): 4,\n",
       " ('pesquisa', 'datafolha', 'neste'): 1,\n",
       " ('pesquisa', 'datafolha', 'covas'): 3,\n",
       " ('pesquisa', 'datafolha', 'cujos'): 1,\n",
       " ('pesquisa', 'datafolha', 'motra'): 1,\n",
       " ('pesquisa', 'datafolha', 'sugere'): 1,\n",
       " ('pesquisa', 'datafolha', 'também'): 1,\n",
       " ('pesquisa', 'datafolha', 'na'): 1,\n",
       " ('pesquisa', 'datafolha', 'sacudiu'): 1,\n",
       " ('pesquisa', 'datafolha', 'fhc'): 6,\n",
       " ('pesquisa', 'datafolha', 'constata'): 1,\n",
       " ('pesquisa', 'datafolha', 'devem'): 1,\n",
       " ('pesquisa', 'datafolha', 'essa'): 1,\n",
       " ('pesquisa', 'datafolha', 'adversários'): 1,\n",
       " ('pesquisa', 'datafolha', 'publicado'): 1,\n",
       " ('pesquisa', 'datafolha', 'mostrava'): 1,\n",
       " ('pesquisa', 'datafolha', 'se'): 1,\n",
       " ('pesquisa', 'datafolha', 'cinco'): 1,\n",
       " ('pesquisa', 'datafolha', 'venceria'): 1,\n",
       " ('pesquisa', 'datafolha', 'lula'): 3,\n",
       " ('pesquisa', 'datafolha', 'tem'): 1,\n",
       " ('pesquisa', 'datafolha', 'causou'): 1,\n",
       " ('pesquisa', 'datafolha', 'setenta'): 1,\n",
       " ('pesquisa', 'datafolha', 'prefere'): 1,\n",
       " ('pesquisa', 'datafolha', 'quércia'): 2,\n",
       " ('pesquisa', 'datafolha', 'indicou'): 1,\n",
       " ('pesquisa', 'datafolha', 'registra'): 1,\n",
       " ('pesquisa', 'datafolha', 'realiza'): 1,\n",
       " ('pesquisa', 'datafolha', 'detecta'): 1,\n",
       " ('pesquisa', 'datafolha', 'apurou'): 1,\n",
       " ('pesquisa', 'datafolha', 'para'): 3,\n",
       " ('pesquisa', 'datafolha', 'contra'): 1,\n",
       " ('pesquisa', 'datafolha', 'demonstra'): 1,\n",
       " ('pesquisa', 'datafolha', 'adotou'): 1,\n",
       " ('pesquisa', 'datafolha', 'abateu'): 1,\n",
       " ('pesquisa', 'datafolha', 'antes'): 1,\n",
       " ('pesquisa', 'datafolha', 'pode'): 1,\n",
       " ('pesquisa', 'datafolha', 'aparece'): 1,\n",
       " ('pesquisa', 'datafolha', 'são'): 1,\n",
       " ('pesquisa', 'datafolha', 'mais'): 1,\n",
       " ('pesquisa', 'datafolha', 'anterior'): 3,\n",
       " ('pesquisa', 'datafolha', 'nunca'): 2,\n",
       " ('pesquisa', 'datafolha', 'como'): 2,\n",
       " ('pesquisa', 'datafolha', 'apura'): 1,\n",
       " ('pesquisa', 'datafolha', 'mostrando'): 1,\n",
       " ('pesquisa', 'datafolha', 'constatou'): 1,\n",
       " ('pesquisa', 'datafolha', 'sessenta'): 1,\n",
       " ('pesquisa', 'datafolha', 'debatem'): 1,\n",
       " ('pesquisa', 'datafolha', 'informa'): 1,\n",
       " ('pesquisa', 'datafolha', 'rossi'): 2,\n",
       " ('pesquisa', 'datafolha', 'parece'): 1,\n",
       " ('pesquisa', 'datafolha', 'já'): 1,\n",
       " ('pesquisa', 'datafolha', 'as'): 2,\n",
       " ('pesquisa', 'datafolha', 'dirceu'): 1,\n",
       " ('pesquisa', 'datafolha', 'disse'): 1,\n",
       " ('pesquisa', 'datafolha', 'soma'): 1,\n",
       " ('pesquisa', 'datafolha', 'entrevistou'): 1,\n",
       " ('pesquisa', 'datafolha', 'aumentando'): 1,\n",
       " ('pesquisa', 'datafolha', 'brizola'): 1,\n",
       " ('pesquisa', 'datafolha', 'quase'): 1,\n",
       " ('pesquisa', 'datafolha', 'quer'): 1}"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_next_words(sentence, n_grams, n_plus1_grams):\n",
    "    full_sentences = {}\n",
    "    if n_grams.get(sentence, 0) == 0:\n",
    "        print (f'Sentença {sentence} não encontrada')\n",
    "        return full_sentences\n",
    "\n",
    "    for full_sentence in tqdm(n_plus1_grams.keys()):\n",
    "        if full_sentence[:-1] == sentence:\n",
    "            full_sentences[full_sentence] = n_plus1_grams.get(full_sentence)\n",
    "\n",
    "    return full_sentences\n",
    "\n",
    "sentence = ('pesquisa', 'datafolha')\n",
    "next_words = get_next_words(sentence, n_grams, n_plus1_grams)\n",
    "next_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11475645/11475645 [00:09<00:00, 1204350.08it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{('brasília', 'pesquisa', 'datafolha'): 4,\n",
       " ('última', 'pesquisa', 'datafolha'): 94,\n",
       " ('na', 'pesquisa', 'datafolha'): 53,\n",
       " ('da', 'pesquisa', 'datafolha'): 46,\n",
       " ('segundo', 'pesquisa', 'datafolha'): 67,\n",
       " ('de', 'pesquisa', 'datafolha'): 26,\n",
       " ('nova', 'pesquisa', 'datafolha'): 3,\n",
       " ('a', 'pesquisa', 'datafolha'): 119,\n",
       " ('pela', 'pesquisa', 'datafolha'): 9,\n",
       " ('em', 'pesquisa', 'datafolha'): 14,\n",
       " ('namorados', 'pesquisa', 'datafolha'): 1,\n",
       " ('conforme', 'pesquisa', 'datafolha'): 5,\n",
       " ('<s>', 'pesquisa', 'datafolha'): 77,\n",
       " ('lidera', 'pesquisa', 'datafolha'): 1,\n",
       " ('hoje', 'pesquisa', 'datafolha'): 1,\n",
       " ('recente', 'pesquisa', 'datafolha'): 18,\n",
       " ('fonte', 'pesquisa', 'datafolha'): 3,\n",
       " ('com', 'pesquisa', 'datafolha'): 4,\n",
       " ('primeira', 'pesquisa', 'datafolha'): 5,\n",
       " ('paulo', 'pesquisa', 'datafolha'): 1,\n",
       " ('útlima', 'pesquisa', 'datafolha'): 1,\n",
       " ('uma', 'pesquisa', 'datafolha'): 7,\n",
       " ('à', 'pesquisa', 'datafolha'): 3,\n",
       " ('econômica', 'pesquisa', 'datafolha'): 1,\n",
       " ('apura', 'pesquisa', 'datafolha'): 1,\n",
       " ('próxima', 'pesquisa', 'datafolha'): 1,\n",
       " ('revela', 'pesquisa', 'datafolha'): 6,\n",
       " ('ps', 'pesquisa', 'datafolha'): 1,\n",
       " ('07/07', 'pesquisa', 'datafolha'): 1,\n",
       " ('mostra', 'pesquisa', 'datafolha'): 1,\n",
       " ('entanto', 'pesquisa', 'datafolha'): 1,\n",
       " ('maio', 'pesquisa', 'datafolha'): 1,\n",
       " ('esta', 'pesquisa', 'datafolha'): 2,\n",
       " ('diz', 'pesquisa', 'datafolha'): 1,\n",
       " ('aponta', 'pesquisa', 'datafolha'): 1,\n",
       " ('segunda', 'pesquisa', 'datafolha'): 1,\n",
       " ('rio', 'pesquisa', 'datafolha'): 1,\n",
       " ('moeda', 'pesquisa', 'datafolha'): 1,\n",
       " ('indica', 'pesquisa', 'datafolha'): 1,\n",
       " ('e', 'pesquisa', 'datafolha'): 1,\n",
       " ('por', 'pesquisa', 'datafolha'): 2}"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_previous_words(sentence, n_grams, n_plus1_grams):\n",
    "    full_sentences = {}\n",
    "    if n_grams.get(sentence, 0) == 0:\n",
    "        print (f'Sentença {sentence} não encontrada')\n",
    "        return full_sentences\n",
    "\n",
    "    for full_sentence in tqdm(n_plus1_grams.keys()):\n",
    "        if full_sentence[1:] == sentence:\n",
    "            full_sentences[full_sentence] = n_plus1_grams.get(full_sentence)\n",
    "\n",
    "    return full_sentences\n",
    "\n",
    "sentence = ('pesquisa', 'datafolha')\n",
    "get_previous_words(sentence, n_grams, n_plus1_grams)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculando a _backward probability_\n",
    "\n",
    "$$P(word|sentence) = \\frac{Count(word+sentence)}{Count(sentence)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ocorrências da sentença ('datafolha', 'publicada', 'hoje'): 24\n",
      "Ocorrências da sentença ('pesquisa', 'datafolha', 'publicada', 'hoje'): 20\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8333333333333334"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_backward_probability(sentence, word, n_grams, n_plus1_grams, vocabulary):\n",
    "    if word not in vocabulary.keys():\n",
    "        print (f'Word {word} not in vocabulary')\n",
    "        return 0\n",
    "    full_sentence = (word, *sentence)\n",
    "    sentence_occurrences = n_grams.get(sentence, 0)\n",
    "    full_sentence_occurences = n_plus1_grams.get(full_sentence, 0)\n",
    "\n",
    "    print (f'Ocorrências da sentença {sentence}: {sentence_occurrences}')\n",
    "    print (f'Ocorrências da sentença {full_sentence}: {full_sentence_occurences}')\n",
    "\n",
    "    if sentence_occurrences == 0:\n",
    "        return 0\n",
    "\n",
    "    return full_sentence_occurences/sentence_occurrences\n",
    "\n",
    "sentence = ('datafolha', 'publicada', 'hoje')\n",
    "previous_word = 'pesquisa'\n",
    "prob = get_backward_probability(sentence, previous_word, n_grams, n_plus1_grams, vocabulary)\n",
    "prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_plus1_grams.get(('brasília', 'pesquisa', 'datafolha', 'publicada', 'hoje', 'revela'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>questions</th>\n",
       "      <th>corrAnswer</th>\n",
       "      <th>sentID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>###### Por enquanto devemos continuar com noss...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>###### Não consigo imaginar sobre o que mais v...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>###### A porta foi fechada atrás dele e Sérgio...</td>\n",
       "      <td>Havia outros três homens na cela com Sérgio?</td>\n",
       "      <td>não</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>###### Caroline pegou os pratos vazios da mesa...</td>\n",
       "      <td>Caroline colocou os pratos vazios na pia?</td>\n",
       "      <td>não</td>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>###### De manhã era bom se levantar e não ter ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-</td>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                target  \\\n",
       "199  ###### Por enquanto devemos continuar com noss...   \n",
       "200  ###### Não consigo imaginar sobre o que mais v...   \n",
       "201  ###### A porta foi fechada atrás dele e Sérgio...   \n",
       "202  ###### Caroline pegou os pratos vazios da mesa...   \n",
       "203  ###### De manhã era bom se levantar e não ter ...   \n",
       "\n",
       "                                        questions corrAnswer  sentID  \n",
       "199                                           NaN          -     200  \n",
       "200                                           NaN          -     201  \n",
       "201  Havia outros três homens na cela com Sérgio?        não     202  \n",
       "202     Caroline colocou os pratos vazios na pia?        não     203  \n",
       "203                                           NaN          -     204  "
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sentences = pd.read_excel('sentences.xlsx', engine='openpyxl')\n",
    "df_sentences.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>n_grams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>###### Ana se descontrolou e riu</td>\n",
       "      <td>(descontrolou, e, riu)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>###### José escreveu no envelope</td>\n",
       "      <td>(escreveu, no, envelope)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>###### Ele ficou encostado na parede</td>\n",
       "      <td>(encostado, na, parede)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>###### Helena correu para o banheiro</td>\n",
       "      <td>(para, o, banheiro)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>###### Rogério sorriu e sentou-se</td>\n",
       "      <td>(sorriu, e, sentou-se)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>###### Por enquanto devemos continuar com noss...</td>\n",
       "      <td>(como, costumávamos, fazer)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>###### Não consigo imaginar sobre o que mais v...</td>\n",
       "      <td>(que, não, falaria)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>###### A porta foi fechada atrás dele e Sérgio...</td>\n",
       "      <td>(homens, na, cela)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>###### Caroline pegou os pratos vazios da mesa...</td>\n",
       "      <td>(migalhas, da, mesa)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>###### De manhã era bom se levantar e não ter ...</td>\n",
       "      <td>(café, da, manhã)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>204 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                target  \\\n",
       "0                     ###### Ana se descontrolou e riu   \n",
       "1                     ###### José escreveu no envelope   \n",
       "2                 ###### Ele ficou encostado na parede   \n",
       "3                 ###### Helena correu para o banheiro   \n",
       "4                    ###### Rogério sorriu e sentou-se   \n",
       "..                                                 ...   \n",
       "199  ###### Por enquanto devemos continuar com noss...   \n",
       "200  ###### Não consigo imaginar sobre o que mais v...   \n",
       "201  ###### A porta foi fechada atrás dele e Sérgio...   \n",
       "202  ###### Caroline pegou os pratos vazios da mesa...   \n",
       "203  ###### De manhã era bom se levantar e não ter ...   \n",
       "\n",
       "                         n_grams  \n",
       "0         (descontrolou, e, riu)  \n",
       "1       (escreveu, no, envelope)  \n",
       "2        (encostado, na, parede)  \n",
       "3            (para, o, banheiro)  \n",
       "4         (sorriu, e, sentou-se)  \n",
       "..                           ...  \n",
       "199  (como, costumávamos, fazer)  \n",
       "200          (que, não, falaria)  \n",
       "201           (homens, na, cela)  \n",
       "202         (migalhas, da, mesa)  \n",
       "203            (café, da, manhã)  \n",
       "\n",
       "[204 rows x 2 columns]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_ngrams(sentence, n):\n",
    "    return tuple(sentence.split(' ')[-n:])\n",
    "df_sentences['n_grams'] = df_sentences['target'].apply(lambda x: get_ngrams(x, n_gram))\n",
    "df_sentences[['target', 'n_grams']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ocorrências da sentença ('por', 'enquanto', 'devemos'): 0\n",
      "Ocorrências da sentença ('por', 'enquanto', 'devemos', 'continuar'): 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = ('por', 'enquanto', 'devemos')\n",
    "next_word = 'continuar'\n",
    "prob = get_forward_probability(sentence, next_word, n_grams, n_plus1_grams, vocabulary)\n",
    "prob"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('gflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2a208ed1ca89c7453353a0367d008f52655cfa1cd6790023707c7f220a959b2f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
